<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Assignments</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Journal.html">Journal</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Assignments</h1>

</div>


<p>This page will contain all the assignments you submit for the class.</p>
<div id="instructions-for-all-assignments" class="section level3">
<h3>Instructions for all assignments</h3>
<p>I want you to submit your assignment as a PDF, so I can keep a record of what the code looked like that day. I also want you to include your answers on your personal GitHub website. This will be good practice for editing your website and it will help you produce something you can keep after the class is over.</p>
<ol style="list-style-type: decimal">
<li><p>Download the Assignment1.Rmd file from Canvas. You can use this as a template for writing your answers. It’s the same as what you can see on my website in the Assignments tab. Once we’re done with this I’ll edit the text on the website to include the solutions.</p></li>
<li><p>On RStudio, open a new R script in RStudio (File &gt; New File &gt; R Script). This is where you can test out your R code. You’ll write your R commands and draw plots here.</p></li>
<li><p>Once you have finalized your code, copy and paste your results into this template (Assignment 1.Rmd). For example, if you produced a plot as the solution to one of the problems, you can copy and paste the R code in R markdown by using the <code>``{r} ```</code> command. Answer the questions in full sentences and Save.</p></li>
<li><p>Produce a PDF file with your answers. To do this, knit to PDF (use Knit button at the top of RStudio), locate the PDF file in your docs folder (it’s in the same folder as the Rproj), and submit that on on Canvas in Assignment 1.</p></li>
<li><p>Build Website, go to GitHub desktop, commit and push. Now your solutions should be on your website as well.</p></li>
</ol>
</div>
<div id="assignment-1" class="section level1">
<h1>Assignment 1</h1>
<p><strong>Collaborators: Lorem Ipsum. </strong></p>
<p>This assignment is due on Canvas on Monday 9/20 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<div id="problem-1" class="section level3">
<h3>Problem 1</h3>
<p>Install the datasets package on the console below using <code>install.packages("datasets")</code>. Now load the library.</p>
<pre class="r"><code>library(datasets)</code></pre>
<p>Load the USArrests dataset and rename it <code>dat</code>. Note that this dataset comes with R, in the package datasets, so there’s no need to load data from your computer. Why is it useful to rename the dataset?</p>
<p>It is useful to rename datasets because it gives us a shorthand to work with. So in this case, instead of referring to the data with “USArrests” we can ref to it with dat.</p>
<pre class="r"><code>dat &lt;- USArrests</code></pre>
</div>
<div id="problem-2" class="section level3">
<h3>Problem 2</h3>
<p>Use this command to make the state names into a new variable called State.</p>
<pre class="r"><code>dat$state &lt;- tolower(rownames(USArrests))</code></pre>
<p>This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.</p>
<p>List the variables contained in the dataset <code>USArrests</code>.</p>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##      Murder          Assault         UrbanPop          Rape      
##  Min.   : 0.800   Min.   : 45.0   Min.   :32.00   Min.   : 7.30  
##  1st Qu.: 4.075   1st Qu.:109.0   1st Qu.:54.50   1st Qu.:15.07  
##  Median : 7.250   Median :159.0   Median :66.00   Median :20.10  
##  Mean   : 7.788   Mean   :170.8   Mean   :65.54   Mean   :21.23  
##  3rd Qu.:11.250   3rd Qu.:249.0   3rd Qu.:77.75   3rd Qu.:26.18  
##  Max.   :17.400   Max.   :337.0   Max.   :91.00   Max.   :46.00</code></pre>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;Murder&quot;   &quot;Assault&quot;  &quot;UrbanPop&quot; &quot;Rape&quot;</code></pre>
<p>The four variables are “Murder”, “Assault”, “UrbanPop”, and “Rape” (and the state variable which we created).</p>
</div>
<div id="problem-3" class="section level3">
<h3>Problem 3</h3>
<p>What type of variable (from the DVB chapter) is <code>Murder</code>?</p>
<p>Answer: It is a quantitative variable because this variable is representing some numerical value in relation to a state.</p>
<p>What R Type of variable is it?</p>
<p>Answer: This variable is a character because the word murder itself is represented in a string format.</p>
</div>
<div id="problem-4" class="section level3">
<h3>Problem 4</h3>
<p>What information is contained in this dataset, in general? What do the numbers mean?</p>
<p>Answer: The dataset contains information about murder, assault, and rape. Additionally, it seems to give us some numbers for a states urban population to help see the relation aswell. These numbers show us the relationship with often they are occuring) of these different variables in different states. For example a number for murder is telling it there was some amount of murders within this state (and we can compare this to other states by seeing how much more or less these crimes occur in other states).</p>
</div>
<div id="problem-5" class="section level3">
<h3>Problem 5</h3>
<p>Draw a histogram of <code>Murder</code> with proper labels and title.</p>
<pre class="r"><code>hist(dat$Murder, main = &quot;Histogram of Murder&quot;, xlab = &quot;States&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="problem-6" class="section level3">
<h3>Problem 6</h3>
<p>Please summarize <code>Murder</code> quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?</p>
<pre class="r"><code>  summary(dat$Murder)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.800   4.075   7.250   7.788  11.250  17.400</code></pre>
<p>Min. 1st Qu. Median Mean 3rd Qu. Max. 0.800 4.075 7.250 7.788 11.250 17.400</p>
<p>The mean is 7.788 and the median and 7.250. The mean is the average of the dataset while the median gives us a central value of our dataset. A quartile tells us the variability around the median. So the 1st and 3rd quartiles show us the variability before the median is reached and after the median is reached. R gives us this data to show us where it might be more or less skewed.</p>
</div>
<div id="problem-7" class="section level3">
<h3>Problem 7</h3>
<p>Repeat the same steps you followed for <code>Murder</code>, for the variables <code>Assault</code> and <code>Rape</code>. Now plot all three histograms together. You can do this by using the command <code>par(mfrow=c(3,1))</code> and then plotting each of the three.</p>
<p>Answer (for data on the other two variables) : For assaults, the mean is 170.8 and the median and 159.0.</p>
<p>For rapes, the mean is 21.23 and the median and 20.10.</p>
<pre class="r"><code>summary(dat$Murder)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.800   4.075   7.250   7.788  11.250  17.400</code></pre>
<pre class="r"><code>summary(dat$Assault)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    45.0   109.0   159.0   170.8   249.0   337.0</code></pre>
<pre class="r"><code>summary(dat$Rape)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    7.30   15.07   20.10   21.23   26.18   46.00</code></pre>
<pre class="r"><code>par(mfrow=c(3,1))
hist(dat$Assault, main = &quot;Histogram of Assault&quot;, xlab = &quot;States&quot;)
hist(dat$Murder, main = &quot;Histogram of Murder&quot;, xlab = &quot;States&quot;)
hist(dat$Rape, main = &quot;Histogram of Rape&quot;, xlab = &quot;States&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-7-1.png" width="480" /></p>
<p>What does the command par do, in your own words (you can look this up by asking R <code>?par</code>)?</p>
<p>Answer: It helps us combine multiple plots that we created into one big vertical plot.</p>
<p>What can you learn from plotting the histograms together?</p>
<p>Answer: We can see the correlation between the data. If there are some points where there is a peak at the same time then we can generalize and say that state could be more dangerous than others. This could work likewise for the converse situation.</p>
</div>
<div id="problem-8" class="section level3">
<h3>Problem 8</h3>
<p>In the console below (not in text), type <code>install.packages("maps")</code> and press Enter, and then type <code>install.packages("ggplot2")</code> and press Enter. This will install the packages so you can load the libraries.</p>
<p>Run this code:</p>
<pre class="r"><code>library(&#39;maps&#39;) 
library(&#39;ggplot2&#39;) 

ggplot(dat, aes(map_id=state, fill=Murder)) + 
  geom_map(map=map_data(&quot;state&quot;)) + 
  expand_limits(x=map_data(&quot;state&quot;)$long, y=map_data(&quot;state&quot;)$lat)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-8-1.png" width="720" /></p>
<p>What does this code do? Explain what each line is doing.</p>
<p>Answer: The first two lines import the libraries map and ggplot2. Line 154 imports dat wants to define the map id of states with murder. The second line is filling out map with state data.The third line maps it out in a x and y axis so we can see the data in states.</p>
</div>
</div>
<div id="assignment-2" class="section level1">
<h1>Assignment 2</h1>
<div id="problem-1-load-data" class="section level2">
<h2>Problem 1: Load data</h2>
<p>Set your working directory to the folder where you downloaded the data.</p>
<pre class="r"><code>setwd(&quot;/Users/akshatshah/Desktop/upenn/crim250/LabJournal&quot;)</code></pre>
</div>
<div id="read-the-data" class="section level2">
<h2>Read the data</h2>
<pre class="r"><code>dat &lt;- read.csv(file = &#39;dat.nsduh.small.1.csv&#39;)</code></pre>
<p>What are the dimensions of the dataset?</p>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 171   7</code></pre>
<p>Answer: There are 171 rows and 7 columns in this dataset.</p>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;mjage&quot;     &quot;cigage&quot;    &quot;iralcage&quot;  &quot;age2&quot;      &quot;sexatract&quot; &quot;speakengl&quot;
## [7] &quot;irsex&quot;</code></pre>
</div>
<div id="problem-2-variables" class="section level2">
<h2>Problem 2: Variables</h2>
<p>Describe the variables in the dataset.</p>
<p>The variables are mjage, ciage, iralcage, age2, sexatract, speakengl, and irsex. They each tell us different things. Mjage tells how old someone was when they first starting using marijuana. Ciage tells how old someone was when they first starting smoking cigs every day. iralcage tells how old someone was when they tried alcohol. age2 tells us hpw old the person currently is. However, this gives us a range because a person could have changes their choice based on previous responses and the questions they say. Irsex tells us their gender. sexatract tells us describes their attraction/sexuality. speakengl tells how well the individual speaks english.</p>
<p>What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data?</p>
<p>This dataset is a survey about national drug use and health. The data is sponsored by the United States Health and Human Services. The sample is a scientific random sample of household addresses. This data gives us a state and nationwide statistics on drug use. This information is used to help with prevention, trend studies, and inform public health policy.</p>
</div>
<div id="problem-3-age-and-gender" class="section level2">
<h2>Problem 3: Age and gender</h2>
<p>What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.</p>
<p>The age distribution is more towards the 13-17 year old range. However, when we look at this data we should understand that it can be more of a range since participants could change their answers based on the decisions on they made or what they see fit.</p>
<p>Do you think this age distribution representative of the US population? Why or why not?</p>
<p>I believe this data not a good representative of the US population. We are looking at a younger population that makes up around 35% of the age distribution. So we are leaving out a large majority that can help us see more trends.</p>
<p>Is the sample balanced in terms of gender? If not, are there more females or males?</p>
<p>I believe this data is pretty balanced. There is a pretty even distribution but for some of the ages we can see that there is a clear majority like for 17.</p>
<p>Use this code to draw a stacked bar plot to view the relationship between sex and age. What can you conclude from this plot?</p>
<pre class="r"><code>tab.agesex &lt;- table(dat$irsex, dat$age2)

barplot(tab.agesex,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;Age category&quot;, ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.agesex),
        beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="problem-4-substance-use" class="section level2">
<h2>Problem 4: Substance use</h2>
<p>For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier?</p>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##      mjage           cigage         iralcage          age2      
##  Min.   : 7.00   Min.   :10.00   Min.   : 5.00   Min.   : 4.00  
##  1st Qu.:14.00   1st Qu.:15.00   1st Qu.:13.00   1st Qu.:13.00  
##  Median :16.00   Median :17.00   Median :15.00   Median :15.00  
##  Mean   :15.99   Mean   :17.65   Mean   :14.95   Mean   :13.98  
##  3rd Qu.:17.50   3rd Qu.:19.00   3rd Qu.:17.00   3rd Qu.:15.00  
##  Max.   :35.00   Max.   :50.00   Max.   :23.00   Max.   :17.00  
##    sexatract       speakengl        irsex      
##  Min.   : 1.00   Min.   :1.00   Min.   :1.000  
##  1st Qu.: 1.00   1st Qu.:1.00   1st Qu.:1.000  
##  Median : 1.00   Median :1.00   Median :1.000  
##  Mean   : 3.07   Mean   :1.07   Mean   :1.468  
##  3rd Qu.: 1.00   3rd Qu.:1.00   3rd Qu.:2.000  
##  Max.   :99.00   Max.   :3.00   Max.   :2.000</code></pre>
<p>Looking at the summary of the data, we can see on average what is used earlier on. Alcohol seems to be used the earliest at an average of 14.95. Then it is mjage at 15.99 Finally, it is cigage at 17.65.</p>
</div>
<div id="problem-5-sexual-attraction" class="section level2">
<h2>Problem 5: Sexual attraction</h2>
<p>What does the distribution of sexual attraction look like? Is this what you expected?</p>
<pre class="r"><code>table(dat$sexatract)</code></pre>
<pre><code>## 
##   1   2   3   4   5   6  99 
## 136  16   9   3   3   1   3</code></pre>
<p>We see that the largest amount of people (136) chose 1. Yes, this is what I expected since it is the norm to be heterosexual.</p>
<p>What is the distribution of sexual attraction by gender?</p>
<pre class="r"><code>table(dat$sexatract, dat$irsex)</code></pre>
<pre><code>##     
##       1  2
##   1  82 54
##   2   3 13
##   3   0  9
##   4   1  2
##   5   2  1
##   6   1  0
##   99  2  1</code></pre>
<p>By gender, the distribution is the same in that the majority of both gender are attracted to the opposite gender. However, more females chose other options.</p>
</div>
<div id="problem-6-english-speaking" class="section level2">
<h2>Problem 6: English speaking</h2>
<p>What does the distribution of English speaking look like in the sample? Is this what you might expect for a random sample of the US population?</p>
<pre class="r"><code>table(dat$speakengl)</code></pre>
<pre><code>## 
##   1   2   3 
## 161   8   2</code></pre>
<p>The majority of people chose that they speak english very well. And there were very few who chose well and not well (10 total). This is probably what I would expect since it is the dominant language.</p>
<p>Are there more English speaker females or males?</p>
<pre class="r"><code>table(dat$speakengl, dat$irsex)</code></pre>
<pre><code>##    
##      1  2
##   1 84 77
##   2  7  1
##   3  0  2</code></pre>
<p>There are more English speakers who are male than female.</p>
</div>
</div>
<div id="exam-1" class="section level1">
<h1>Exam 1</h1>
<div id="instructions" class="section level2">
<h2>Instructions</h2>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (fatal-police-shootings-data.csv) onto that folder, and save your Exam 1.Rmd file in the same folder.</p></li>
<li><p>Download the README.md file. This is the codebook.</p></li>
<li><p>Load the data into an R data frame.</p></li>
</ol>
<pre class="r"><code>dat &lt;- read.csv(file = &quot;Crim 250 - Exam 1/fatal-police-shootings-data.csv&quot;)</code></pre>
</div>
<div id="problem-1-10-points" class="section level2">
<h2>Problem 1 (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>Describe the dataset. This is the source: <a href="https://github.com/washingtonpost/data-police-shootings" class="uri">https://github.com/washingtonpost/data-police-shootings</a> . Write two sentences (max.) about this.</li>
</ol>
<p>This is a dataset that is compiled by the Washington Post of victims of fatal police shootings. At each row, we are given a victim’s name and data on the situation that was at hand.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>How many observations are there in the data frame?</li>
</ol>
<pre class="r"><code>dim((dat))</code></pre>
<pre><code>## [1] 6594   17</code></pre>
<p>We know there are 6594 rows and 17 columns. We know that the number of observations are the number of rows. Therefore there are 6593 observations (not including the first row since this is the title of the columns).</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Look at the names of the variables in the data frame. Describe what “body_camera”, “flee”, and “armed” represent, according to the codebook. Again, only write one sentence (max) per variable.</li>
</ol>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>##  [1] &quot;id&quot;                      &quot;name&quot;                   
##  [3] &quot;date&quot;                    &quot;manner_of_death&quot;        
##  [5] &quot;armed&quot;                   &quot;age&quot;                    
##  [7] &quot;gender&quot;                  &quot;race&quot;                   
##  [9] &quot;city&quot;                    &quot;state&quot;                  
## [11] &quot;signs_of_mental_illness&quot; &quot;threat_level&quot;           
## [13] &quot;flee&quot;                    &quot;body_camera&quot;            
## [15] &quot;longitude&quot;               &quot;latitude&quot;               
## [17] &quot;is_geocoding_exact&quot;</code></pre>
<p>Body camera is a variable that is telling us if an officer was wearing a body camera and if it was recording what happened.</p>
<p>Flee is a variable that was indicating if the victim was moving away, and if they were fleeing this tells us by what method.</p>
<p>Armed is a variable that tells if the officer believe they had some tool that could inflict damage.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>What are three weapons that you are surprised to find in the “armed” variable? Make a table of the values in “armed” to see the options.</li>
</ol>
<pre class="r"><code>table(dat$armed)</code></pre>
<pre><code>## 
##                                                   air conditioner 
##                              207                                1 
##                       air pistol                   Airsoft pistol 
##                                1                                3 
##                               ax                         barstool 
##                               24                                1 
##                     baseball bat          baseball bat and bottle 
##                               20                                1 
## baseball bat and fireplace poker           baseball bat and knife 
##                                1                                1 
##                            baton                           BB gun 
##                                6                               15 
##               BB gun and vehicle                     bean-bag gun 
##                                1                                1 
##                      beer bottle                       binoculars 
##                                3                                1 
##                     blunt object                           bottle 
##                                5                                1 
##                    bow and arrow                       box cutter 
##                                1                               13 
##                            brick              car, knife and mace 
##                                2                                1 
##                          carjack                            chain 
##                                1                                3 
##                        chain saw                         chainsaw 
##                                2                                1 
##                            chair              claimed to be armed 
##                                4                                1 
##               contractor&#39;s level                   cordless drill 
##                                1                                1 
##                         crossbow                          crowbar 
##                                9                                5 
##                        fireworks                         flagpole 
##                                1                                1 
##                       flashlight                      garden tool 
##                                2                                2 
##                      glass shard                          grenade 
##                                4                                1 
##                              gun                      gun and car 
##                             3798                               12 
##                    gun and knife                  gun and machete 
##                               22                                3 
##                    gun and sword                  gun and vehicle 
##                                1                               17 
##              guns and explosives                           hammer 
##                                3                               18 
##                       hand torch                          hatchet 
##                                1                               14 
##                  hatchet and gun                         ice pick 
##                                2                                1 
##                incendiary device                            knife 
##                                2                              955 
##                knife and vehicle                 lawn mower blade 
##                                1                                2 
##                          machete                  machete and gun 
##                               51                                1 
##                     meat cleaver                  metal hand tool 
##                                6                                2 
##                     metal object                       metal pipe 
##                                5                               16 
##                       metal pole                       metal rake 
##                                4                                1 
##                      metal stick                       microphone 
##                                3                                1 
##                       motorcycle                         nail gun 
##                                1                                1 
##                              oar                       pellet gun 
##                                1                                3 
##                              pen                     pepper spray 
##                                1                                2 
##                         pick-axe                    piece of wood 
##                                4                                7 
##                             pipe                        pitchfork 
##                                7                                2 
##                             pole                   pole and knife 
##                                3                                2 
##                  railroad spikes                             rock 
##                                1                                7 
##                    samurai sword                         scissors 
##                                4                                9 
##                      screwdriver                     sharp object 
##                               16                               14 
##                           shovel                            spear 
##                                7                                2 
##                          stapler              straight edge razor 
##                                1                                5 
##                            sword                            Taser 
##                               23                               34 
##                        tire iron                       toy weapon 
##                                4                              226 
##                          unarmed                     undetermined 
##                              421                              188 
##                   unknown weapon                          vehicle 
##                               82                              213 
##                  vehicle and gun              vehicle and machete 
##                                8                                1 
##                    walking stick                       wasp spray 
##                                1                                1 
##                           wrench 
##                                1</code></pre>
<p>I am suprised to see pen, binoculars, and contractor’s level.</p>
</div>
<div id="problem-2-10-points" class="section level2">
<h2>Problem 2 (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>Describe the age distribution of the sample. Is this what you would expect to see?</li>
</ol>
<pre class="r"><code>hist(dat$age, main = &quot;Histogram of Age Distribution&quot;, xlab = &quot;Age (in years)&quot;, xlim = c(0, 100))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>This distribution is skewed to the right. This isn’t exactly what I expected, (I thought it would be skewed even more to the right.) because I believed that victims would be a lot younger.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.</li>
</ol>
<pre class="r"><code>summary(dat$age)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    6.00   27.00   35.00   37.12   45.00   91.00     308</code></pre>
<p>I would use mean to understand the center of the age distribution because I don’t believe there are enough outliers/extremes that would skew this result substantially. The mean gives us an average over our data. We can see that the average age of victims for police fatal shootings were 37.12 years old.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe the gender distribution of the sample. Do you find this surprising?</li>
</ol>
<pre class="r"><code>table(dat$gender)</code></pre>
<pre><code>## 
##         F    M 
##    3  293 6298</code></pre>
<p>Within this dataset, there are significantly more men than women (6005 more). This is not surprising because statistics have shown that men have been higher arrest rate than women. Since men have a higher arrest rate than women and more encounters with police, I expected there to be more men than women within this dataset. Additonally, there were 3 blank indexes for this data and it was not taken into account for the calculations above since it is inconclusive.</p>
</div>
<div id="problem-3-10-points" class="section level2">
<h2>Problem 3 (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?</li>
</ol>
<pre class="r"><code>table(dat$body_camera)</code></pre>
<pre><code>## 
## False  True 
##  5684   910</code></pre>
<p>Only 910 officers had a body camera according to this dataset. This means that only 14% of incidents had a body camera. This is extremely suprising that is so low because people are losing their lives and a proportion of officers have no concrete evidence of the situation due to no body camera.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>In how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?</li>
</ol>
<pre class="r"><code>table(dat$flee)</code></pre>
<pre><code>## 
##                     Car        Foot Not fleeing       Other 
##         491        1058         845        3952         248</code></pre>
<p>Out of 6103 incidents that recorded something in the fleeing category, 2151 victims were fleeing. This means about 35% of people who were a victim of a fatal police shooting were fleeing. I suspected a larger proportion of people were fleeing, but this dataset refutes that idea. Additionally, there is 491 indexes of data that are blank for fleeing, so this was removed from the total number of incidents and the proportion since it is inconclusive.</p>
</div>
<div id="problem-4-10-points---answer-only-one-of-these-a-or-b." class="section level2">
<h2>Problem 4 (10 points) - Answer only one of these (a or b).</h2>
<ol style="list-style-type: lower-alpha">
<li>Describe the relationship between the variables “body camera” and “flee” using a stacked barplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the options for “flee”, each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<p><strong>Your answer here.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<pre class="r"><code>boxplot(dat$age~factor(dat$race), ylab = &quot;Age&quot;, xlab = &quot;Race&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>We see from the data that some races have a slightly lower mean age than others. For examples, the mean age for white people looks to be around 40, while the mean age for black people seems to be about 35. Additionally, some races have a lot more outliers than others. For example, asian people have no outliers while black people have a lot of outliers. It is hard to make a concrete conclusion based on this relationship, but we can observe that there are clear small differences that we can observe (as stated above) from the different races and their ages. Furthermore, the first category simple represent people who did not have a specified age (left blank in the dataset). I did not omit this data because I think it could still be important to see this in relation to the other data.</p>
</div>
<div id="extra-credit-10-points" class="section level2">
<h2>Extra credit (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>What does this code tell us?</li>
</ol>
<pre class="r"><code>mydates &lt;- as.Date(dat$date)
head(mydates)
(mydates[length(mydates)] - mydates[1])</code></pre>
<p>This data tells us how long it has been since the first entry within this dataset to the most recent entry within the dataset. We are taking the first index because the 0th index states the name of each column, and we are taking the last index to get the last entry. The difference is 2458 days which is about 6.7 years. This makes sense because this dataset was created in 2015 and we are about 6 and 3/4 years from this time.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>On Friday, a new report was published that was described as follows by The Guardian: “More than half of US police killings are mislabelled or not reported, study finds.” Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?</li>
</ol>
<p>I believe this is because of bias. Police who have been apart of police killings are going to defend themselves. In order to do so, they might underreport or mislabel the incident in order to save face and justify the actions they took. Additionally, co workers of police who have been apart of such an incident may look to defend each other building even more of a bias.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Regarding missing values in problem 4, do you see any? If so, do you think that’s all that’s missing from the data?</li>
</ol>
<p>In problem 4, there were clear missing values (race was not defined). I believe there is more missing from the data. If we were to look closer into the data we can see that sometimes, for example, gender isn’t specified. Additionally, another data that has missing values is fleeing (491 are blank).</p>
</div>
</div>
<div id="exam-2" class="section level1">
<h1>Exam 2</h1>
<div id="instructions-1" class="section level2">
<h2>Instructions</h2>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.</p></li>
<li><p>Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: <strong>“Does having more funding in a police department lead to fewer incidents of police brutality?”</strong></p></li>
<li><p>Codebook:</p></li>
</ol>
<ul>
<li>funds: How much funding the police department received in that year in millions of dollars.</li>
<li>po.brut: How many incidents of police brutality were reported by the department that year.</li>
<li>po.dept.code: Police department code</li>
</ul>
</div>
<div id="problem-1-eda-10-points" class="section level2">
<h2>Problem 1: EDA (10 points)</h2>
<p>Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.</p>
<pre class="r"><code>dat &lt;- read.csv(file = &#39;sim.data.csv&#39;)
names(dat)</code></pre>
<pre><code>## [1] &quot;po.dept.code&quot; &quot;funds&quot;        &quot;po.brut&quot;</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##   po.dept.code        funds          po.brut     
##  Min.   :  1.00   Min.   :21.40   Min.   : 0.00  
##  1st Qu.: 50.75   1st Qu.:51.67   1st Qu.:14.00  
##  Median :100.50   Median :59.75   Median :19.00  
##  Mean   :100.50   Mean   :61.04   Mean   :18.14  
##  3rd Qu.:150.25   3rd Qu.:72.17   3rd Qu.:22.00  
##  Max.   :200.00   Max.   :99.70   Max.   :29.00</code></pre>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 200   3</code></pre>
<pre class="r"><code>plot(dat$funds, dat$po.brut,  main=&quot;Relationship between Police Department Funding (in millions) and Police Bruality (per year)&quot;, xlab=&quot;Amount of funding&quot;, ylab=&quot;Number of police brutality incidences per year&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre class="r"><code>cor(dat$funds, dat$po.brut)</code></pre>
<pre><code>## [1] -0.9854706</code></pre>
<p>The dataset has three different variables consisting of the department code, funds, and police brutality. There are 200 observations of different police departments and the number of incidences where police brutality occurred. We see that on average a department gets around 61 million dollars in funding and will have about 18 incidences of police brutality that year. We can see from the graph that there is a clear decrease in the number of police brutality incidences as the amount of funding goes up. Furthermore, we can see that the correlation between these two values is a -0.98 which indicates there is a extremely strong linear relationship (in this case it is a negative one).</p>
</div>
<div id="problem-2-linear-regression-30-points" class="section level2">
<h2>Problem 2: Linear regression (30 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>Perform a simple linear regression to answer the question of interest. To do this, name your linear model “reg.output” and write the summary of the regression by using “summary(reg.output)”.</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE!!
reg.output &lt;- lm(formula = dat$po.brut ~ dat$funds, data = dat)
summary(reg.output)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat$po.brut ~ dat$funds, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9433 -0.2233  0.2544  0.5952  1.1803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.543069   0.282503  143.51   &lt;2e-16 ***
## dat$funds   -0.367099   0.004496  -81.64   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9464 on 198 degrees of freedom
## Multiple R-squared:  0.9712, Adjusted R-squared:  0.971 
## F-statistic:  6666 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Your answer here.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.</li>
</ol>
<p>The estimated coefficient for the slope is -0.367 while the estimated coefficient for the intercept is 40.54. The p-value for the slope is less than 2 x 10^-16 (this is the same of the intercept as well). These slope has a standard error of 0.0045 which means that regression we have is very close to the actual value. This means that there exists a linear relationship between the funds and the incidents statically as each of these p-values are less than 0.05. This means that we can reject the null hypothesis and assert that there is a linear relationship.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE!!
plot(dat$funds, dat$po.brut,  main=&quot;Relationship between Police Department Funding (in millions) and Police Bruality (per year)&quot;, xlab=&quot;Amount of funding&quot;, ylab=&quot;Number of police brutality incidences per year&quot;)
abline(reg.output, col = &quot;red&quot;, lwd=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-33-1.png" width="384" /> Does the line look like a good fit? Why or why not?</p>
<p>For the middle values, the line follows the data precisely. However if we look at the the tail-end of both sides of the data we can see that it isn’t as precise anymore. I believe that this line is an okay fit given it can follow the distribution on average but when it gets to parts of the data where we do not have as much information (the tail ends), the predicted value isn’t as correct.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?</li>
</ol>
<pre class="r"><code>plot(dat$funds, reg.output$residuals, main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Scaled speed&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<pre class="r"><code>plot(reg.output, which=1)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-34-2.png" width="672" /></p>
<pre class="r"><code>plot(dat$funds, dat$po.brut, main=&quot;Relationship between funding and police brutality&quot;, xlab = &quot;Amount of funding&quot;, ylab = &quot;Number of police brutality incidences per year&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-34-3.png" width="672" /></p>
<pre class="r"><code>plot(reg.output, which=3)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-34-4.png" width="672" /></p>
<pre class="r"><code>plot(reg.output, which=5)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-34-5.png" width="672" /></p>
<pre class="r"><code>plot(reg.output, which=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-34-6.png" width="672" /></p>
<p>1.Linearly Assumption: This assumption doesn’t hold because we can clearly see that the red line for the graph on residuals vs fitted is not flat and the residuals vs x has a pattern, therefore this means there is non constant variance.</p>
<p>2.Independence assumption : This doesn’t hold because there is a pattern in our graph for residuals vs x.</p>
<p>3.Equal variance assumption : This assumption probably doesn’t hold because our scale-location plot isn’t straight and there is a pattern with it.</p>
<p>4.Normal Population Assumption : When we look at our normal qq plot, we see that the there is a left skew (the left and the right ends of the tail are lighter and smaller than the normal distribution).</p>
<p>The four assumptions were not satisfied, next time I would try and get more data or I could try and use a different model that would help us see a better relationship, if there exists one.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Answer the question of interest based on your analysis.</li>
</ol>
<p>Because our assumptions do not hold, we can’t use this linear regression model to determine if more funding will lead to a decrease of police brutality. This means the results that we obtained to reject the null hypothesis can not be used and it is inconclusive. The results we obtained are misleading.</p>
</div>
<div id="problem-3-data-ethics-10-points" class="section level2">
<h2>Problem 3: Data ethics (10 points)</h2>
<p>Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?</p>
<p>This dataset gives us the funding a police department receives and the amount of police brutality that occurs. From our data ethics lecture, an issue we could come across is correlation doesn’t imply causation. So even though we have a very high correlation, this doesn’t necessary mean that the two variables are related. People could potentially look at this correlation and see the regression without realizing that our assumption didn’t hold.</p>
<p>This matters because people could use this data or data like this to push a false narrative that could damage people. This is an important example to see that we have to check everything because if we forget and show some false information it could cause people to believe ideas that are not true.</p>
</div>
</div>
<div id="assignment-3" class="section level1">
<h1>Assignment 3</h1>
<p>Load the data.</p>
<pre class="r"><code>library(readr)
library(knitr)
dat.crime &lt;- read_delim(&quot;crime_simple.txt&quot;, delim = &quot;\t&quot;)</code></pre>
<p>This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given.</p>
<p>Here is the codebook:</p>
<p>R: Crime rate: # of offenses reported to police per million population</p>
<p>Age: The number of males of age 14-24 per 1000 population</p>
<p>S: Indicator variable for Southern states (0 = No, 1 = Yes)</p>
<p>Ed: Mean of years of schooling x 10 for persons of age 25 or older</p>
<p>Ex0: 1960 per capita expenditure on police by state and local government</p>
<p>Ex1: 1959 per capita expenditure on police by state and local government</p>
<p>LF: Labor force participation rate per 1000 civilian urban males age 14-24</p>
<p>M: The number of males per 1000 females</p>
<p>N: State population size in hundred thousands</p>
<p>NW: The number of non-whites per 1000 population</p>
<p>U1: Unemployment rate of urban males per 1000 of age 14-24</p>
<p>U2: Unemployment rate of urban males per 1000 of age 35-39</p>
<p>W: Median value of transferable goods and assets or family income in tens of $</p>
<p>X: The number of families per 1000 earning below 1/2 the median income</p>
<p>We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related.</p>
<ol style="list-style-type: decimal">
<li>How many observations are there in the dataset? To what does each observation correspond?</li>
</ol>
<pre class="r"><code>names(dat.crime)</code></pre>
<pre><code>##  [1] &quot;R&quot;   &quot;Age&quot; &quot;S&quot;   &quot;Ed&quot;  &quot;Ex0&quot; &quot;Ex1&quot; &quot;LF&quot;  &quot;M&quot;   &quot;N&quot;   &quot;NW&quot;  &quot;U1&quot;  &quot;U2&quot; 
## [13] &quot;W&quot;   &quot;X&quot;</code></pre>
<pre class="r"><code>dim(dat.crime)</code></pre>
<pre><code>## [1] 47 14</code></pre>
<p>Excluding the first row (because it tells us the names of the columns), there are 46 observations. Each column corresponds to “R” “Age” “S” “Ed” “Ex0” “Ex1” “LF” “M” “N” “NW” “U1” “U2” “W” “X” respectively. In our codebook we see that each of the observations is a different data that was recorded.</p>
<ol start="2" style="list-style-type: decimal">
<li>Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?</li>
</ol>
<p>R ED</p>
<pre class="r"><code>plot(dat.crime$Ed, dat.crime$R, main=&quot;Relationship between reported crime rate and mean years of schooling&quot;, xlab = &quot;Mean of years Schooling x10&quot;, ylab = &quot;Reported Crime Rate&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-37-1.png" width="576" /></p>
<pre class="r"><code>cor(dat.crime$Ed, dat.crime$R)</code></pre>
<pre><code>## [1] 0.3228349</code></pre>
<p>The correlation between these two variables is 0.3328349. I don’t think this correlation is high enough for us to draw a particular conclusion yet.</p>
<ol start="3" style="list-style-type: decimal">
<li>Regress reported crime rate (y) on average education (x) and call this linear model <code>crime.lm</code> and write the summary of the regression by using this code, which makes it look a little nicer <code>{r, eval=FALSE} kable(summary(crime.lm)$coef, digits = 2)</code>.</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE above!

crime.lm &lt;- lm(formula = dat.crime$R ~ dat.crime$Ed, data = dat.crime)
kable(summary(crime.lm)$coef, digits = 2)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-27.40</td>
<td align="right">51.81</td>
<td align="right">-0.53</td>
<td align="right">0.60</td>
</tr>
<tr class="even">
<td align="left">dat.crime$Ed</td>
<td align="right">1.12</td>
<td align="right">0.49</td>
<td align="right">2.29</td>
<td align="right">0.03</td>
</tr>
</tbody>
</table>
<p>This regression has a slope of 1.12 which means for every unit of education that increases the reported crime increases by 1.12. Additionally, we see that the error for this is 0.49 (which is how much is varys from the average). Additionally we have a p value of about 2% (which means that this is significant) and our regression is 2.29 standard deviations away from the 0. Another thing to take note of is the fact that our intercept estimate is quite different in comparison to our slope. The estimate is larger as well as the error. Because of this our P value is not a significant one for the intercept.</p>
<ol start="4" style="list-style-type: decimal">
<li>Are the four assumptions of linear regression satisfied?To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)</li>
</ol>
<pre class="r"><code>plot(dat.crime$Ed, crime.lm$residuals, ylim=c(-15,15), main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Scaled speed&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=1)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-2.png" width="672" /></p>
<pre class="r"><code>plot(dat.crime$Ed, dat.crime$R, main=&quot;Relationship between reported crime rate and mean years of schooling&quot;, xlab = &quot;Mean of years Schooling x10&quot;, ylab = &quot;Reported crime rate&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-3.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=5)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-4.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-5.png" width="672" /></p>
<p>1.Linearly Assumption: Looking at the first two plots for Residuals vs X and Residuals vs Fitted we see that these have no real pattern for the nodes as the red line is almost completely flat.</p>
<ol start="2" style="list-style-type: decimal">
<li>Independence assumption : Looking at Residuals vs X, there seems to be no pattern and the nodes seem random.</li>
</ol>
<p>3.Equal variance assumption : There is a slight unequal amount of variable between points of x = 92 to x = 100, therefore this assumption doesn’t stand.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Normal Population Assumption Our qqplot shows us that our residuals tend to be larger in magnitude and overestimate (on the right side), and our right tail is lighter than the rest for a normal distribution.</p></li>
<li><p>Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?</p></li>
</ol>
<pre class="r"><code>summary(crime.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat.crime$R ~ dat.crime$Ed, data = dat.crime)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -60.061 -27.125  -4.654  17.133  91.646 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  -27.3967    51.8104  -0.529   0.5996  
## dat.crime$Ed   1.1161     0.4878   2.288   0.0269 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 37.01 on 45 degrees of freedom
## Multiple R-squared:  0.1042, Adjusted R-squared:  0.08432 
## F-statistic: 5.236 on 1 and 45 DF,  p-value: 0.02688</code></pre>
<p>Our estimated coefficient of slope is 1.1161. Our standard residual error was 37.01 on 45 degrees of freedom. We have a high p value for our intercept and a p value lower for our slope. For the the relationship to be statistically significant means there exists a relationship between reported crime and average education.</p>
<ol start="6" style="list-style-type: decimal">
<li>How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?</li>
</ol>
<p>Because we have a significant slope value, we can say that we reject the null. For every unit increase of average education, the reported crime rate changes by 1.1161.</p>
<ol start="7" style="list-style-type: decimal">
<li>Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?</li>
</ol>
<p>Based of our linear regression, we can conclude that individuals who receive more education will report crime more often since we obtained a pvalue that was statistically significant. This tells us that there exists some relationship (from the slope), which we can see is increasing as a unit of education increases. However, we need to keep in mind that this test doesn’t have enough data points because it is hard to tell if the equal variance and the normal population assumption pass.</p>
</div>
<div id="assignment-4" class="section level1">
<h1>Assignment 4</h1>
<ol style="list-style-type: decimal">
<li>Installed tidyverse and imported it.</li>
</ol>
<pre class="r"><code>library(tidyverse)
library(ggplot2)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>run mpg dataframe</li>
</ol>
<pre class="r"><code>mpg</code></pre>
<pre><code>## # A tibble: 234 × 11
##    manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class
##    &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;
##  1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…
##  2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…
##  3 audi         a4           2    2008     4 manu… f        20    31 p     comp…
##  4 audi         a4           2    2008     4 auto… f        21    30 p     comp…
##  5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…
##  6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…
##  7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…
##  8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…
##  9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…
## 10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…
## # … with 224 more rows</code></pre>
<p>displ, a car’s engine size, in litres.</p>
<p>hwy, a car’s fuel efficiency on the highway, in miles per gallon (mpg). A car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distanc</p>
<ol start="3" style="list-style-type: decimal">
<li>Creating a ggplot</li>
</ol>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p>The plot shows a negative relationship between engine size (displ) and fuel efficiency (hwy). In other words, cars with big engines use more fuel. Does this confirm or refute your hypothesis about fuel efficiency and engine size?</p>
<p>With ggplot2, you begin a plot with the function ggplot(). ggplot() creates a coordinate system that you can add layers to. The first argument of ggplot() is the dataset to use in the graph. So ggplot(data = mpg) creates an empty graph, but it’s not very interesting so I’m not going to show it here.</p>
<p>You complete your graph by adding one or more layers to ggplot(). The function geom_point() adds a layer of points to your plot, which creates a scatterplot. ggplot2 comes with many geom functions that each add a different type of layer to a plot. You’ll learn a whole bunch of them throughout this chapter.</p>
<p>Each geom function in ggplot2 takes a mapping argument. This defines how variables in your dataset are mapped to visual properties. The mapping argument is always paired with aes(), and the x and y arguments of aes() specify which variables to map to the x and y axes. ggplot2 looks for the mapped variables in the data argument, in this case, mpg.</p>
<p>This can be represented in the following template.</p>
<p>ggplot(data = <DATA>) + <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))</p>
<pre class="r"><code>dim(mpg)</code></pre>
<pre><code>## [1] 234  11</code></pre>
<pre class="r"><code>?mpg

plot(mpg$hwy, mpg$cyl)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-44-1.png" width="672" /> 1. I see nothing 2. There are 234 rows and 11 columns 3. drv is the type of drive train where f = front-wheel drive, r = rear wheel drive, 4 = 4wd 4. Its not useful because it is numerical</p>
<ol start="4" style="list-style-type: decimal">
<li></li>
</ol>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, size = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-2.png" width="672" /></p>
<pre class="r"><code>#&gt; Warning: Using size for a discrete variable is not advised.

# Left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-3.png" width="672" /></p>
<pre class="r"><code># Right
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-4.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-5.png" width="672" /> We can use aes to change how our plots look. This refers to aesthetics and ggplot will change it for us.</p>
<p>shape changes shape (only does 6 groups). alpha changes transparency. color changes color</p>
<p>You can also change the color manually.</p>
<p>Common problems are that people will put the + in the wrong place like here: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy))</p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ cyl)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-46-2.png" width="672" /></p>
<p>One way to add additional variables is with aesthetics. Another way, particularly useful for categorical variables, is to split your plot into facets, subplots that each display one subset of the data.</p>
<p>To facet your plot by a single variable, use facet_wrap(). The first argument of facet_wrap() should be a formula, which you create with ~ followed by a variable name (here “formula” is the name of a data structure in R, not a synonym for “equation”). The variable that you pass to facet_wrap() should be discrete.</p>
<p>We can add a combination of two variable by using facet_grid.</p>
<pre class="r"><code># left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<pre class="r"><code># right
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-47-2.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-47-3.png" width="672" /> We can also work with geometric objects in our plot to help with visualization. Additionally we can also change the linetype so it is different for each unique value.</p>
<p>ggplot provides over 40 geom plots that we can use to help with data visualization</p>
<pre class="r"><code>ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-2.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) +
  geom_smooth(
    mapping = aes(x = displ, y = hwy, color = drv),
    show.legend = FALSE
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-3.png" width="672" /> We can also display multiple geom on a single plot.</p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-2.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-3.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth(data = filter(mpg, class == &quot;subcompact&quot;), se = FALSE)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-4.png" width="672" /> So we can change mapping such that there are layer of aesthetics (helps us specify data in labels). We can also modify the plot such that our object will only mend to some of the data.</p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  stat_count(mapping = aes(x = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-2.png" width="672" /></p>
<p>A simple barplot where the data is grouped by cut. You can use stat_count and geom_bar interchangably since geom_bar has a default stat_count.</p>
<pre class="r"><code>demo &lt;- tribble(
  ~cut,         ~freq,
  &quot;Fair&quot;,       1610,
  &quot;Good&quot;,       4906,
  &quot;Very Good&quot;,  12082,
  &quot;Premium&quot;,    13791,
  &quot;Ideal&quot;,      21551
)

ggplot(data = demo) +
  geom_bar(mapping = aes(x = cut, y = freq), stat = &quot;identity&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-51-1.png" width="672" /> You can also change the stat count.</p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>You might want to override the default mapping from transformed variables to aesthetics. For example, you might want to display a bar chart of proportion, rather than count:</p>
<pre class="r"><code>ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>we can do it for a transformation on statisitcs aswell where we take a stat summary and take the specific val of each category.</p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-2.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-3.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = &quot;identity&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-4.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = &quot;identity&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-5.png" width="672" /> Now, we can change the position such that they can either overlap on each other and see something special about the data.</p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;fill&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;dodge&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-2.png" width="672" /> We can use things like position to see proportion to data or dodge to overlap them.</p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = &quot;jitter&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-56-1.png" width="672" /> We can change our data such that their isn’t overplotting such that the arrangement is now easier to see.</p>
<p>The template for all this is:</p>
<p>ggplot(data = <DATA>) + <GEOM_FUNCTION>( mapping = aes(<MAPPINGS>), stat = <STAT>, position = <POSITION> ) + <COORDINATE_FUNCTION> + <FACET_FUNCTION></p>
<p>“To see this, let’s add position adjustments, stats, coordinate systems, and faceting to our code template:”</p>
<div id="graphics-for-communication" class="section level2">
<h2>Graphics for communication</h2>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(title = &quot;Fuel efficiency generally decreases with engine size&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(
    title = &quot;Fuel efficiency generally decreases with engine size&quot;,
    subtitle = &quot;Two seaters (sports cars) are an exception because of their light weight&quot;,
    caption = &quot;Data from fueleconomy.gov&quot;
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-57-2.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  labs(
    x = &quot;Engine displacement (L)&quot;,
    y = &quot;Highway fuel economy (mpg)&quot;,
    colour = &quot;Car type&quot;
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-57-3.png" width="672" /></p>
<pre class="r"><code>df &lt;- tibble(
  x = runif(10),
  y = runif(10)
)
ggplot(df, aes(x, y)) +
  geom_point() +
  labs(
    x = quote(sum(x[i] ^ 2, i == 1, n)),
    y = quote(alpha + beta + frac(delta, theta))
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-57-4.png" width="672" /> We can put labels in places like the title. You can also add them as subtitles, captions, x, and y. Labels can even be written as mathematical equations.</p>
<p>You can take it a step further and make annotations for specific points</p>
<pre class="r"><code>best_in_class &lt;- mpg %&gt;%
  group_by(class) %&gt;%
  filter(row_number(desc(hwy)) == 1)

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_text(aes(label = model), data = best_in_class)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_label(aes(label = model), data = best_in_class, nudge_y = 2, alpha = 0.5)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-58-2.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_point(size = 3, shape = 1, data = best_in_class) +
  ggrepel::geom_label_repel(aes(label = model), data = best_in_class)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-58-3.png" width="672" /> In this graph, we label the cars that are the best in their class in terms of mpg.</p>
<p>The label is hard to read from one another, so we can modify it such that it is easier to see. Additionally, if you use ggrepel then you can make it so the labels are not right on top of each other.</p>
<pre class="r"><code>class_avg &lt;- mpg %&gt;%
  group_by(class) %&gt;%
  summarise(
    displ = median(displ),
    hwy = median(hwy)
  )
#&gt; `summarise()` ungrouping output (override with `.groups` argument)

ggplot(mpg, aes(displ, hwy, colour = class)) +
  ggrepel::geom_label_repel(aes(label = class),
    data = class_avg,
    size = 6,
    label.size = 0,
    segment.color = NA
  ) +
  geom_point() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<pre class="r"><code>label &lt;- mpg %&gt;%
  summarise(
    displ = max(displ),
    hwy = max(hwy),
    label = &quot;Increasing engine size is \nrelated to decreasing fuel economy.&quot;
  )

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_text(aes(label = label), data = label, vjust = &quot;top&quot;, hjust = &quot;right&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-59-2.png" width="672" /></p>
<pre class="r"><code>label &lt;- tibble(
  displ = Inf,
  hwy = Inf,
  label = &quot;Increasing engine size is \nrelated to decreasing fuel economy.&quot;
)

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_text(aes(label = label), data = label, vjust = &quot;top&quot;, hjust = &quot;right&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-59-3.png" width="672" /> We can turn the legend off and then put annotations near the colors such that they represent what each car type is. Additionally, you can just add a single label to the plot and then write what you want.</p>
<p>If you want to place text exactly where the borders are then you can use INF(which can be positive or negative).</p>
<p>There are nine different possibilities for locations that labels can go in (NESW).</p>
<p>Use geom_hline() and geom_vline() to add reference lines. I often make them thick (size = 2) and white (colour = white), and draw them underneath the primary data layer. That makes them easy to see, without drawing attention away from the data.</p>
<p>Use geom_rect() to draw a rectangle around points of interest. The boundaries of the rectangle are defined by aesthetics xmin, xmax, ymin, ymax.</p>
<p>Use geom_segment() with the arrow argument to draw attention to a point with an arrow. Use aesthetics x and y to define the starting location, and xend and yend to define the end location.</p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  scale_x_continuous() +
  scale_y_continuous() +
  scale_colour_discrete()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-60-2.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_y_continuous(breaks = seq(15, 40, by = 5))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-60-3.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_x_continuous(labels = NULL) +
  scale_y_continuous(labels = NULL)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-60-4.png" width="672" /></p>
<p>Another way we can change how the plot looks for communication is by adjusting the scales of the plot. ggplot will automatically add the scales behind the scenes but you can manually change these how you would like.</p>
<p>There are two primary arguments that affect the appearance of the ticks on the axes and the keys on the legend: breaks and labels. Breaks controls the position of the ticks, or the values associated with the keys. Labels controls the text label associated with each tick/key. The most common use of breaks is to override the default choice:</p>
<p>You can also set the values within these scales (labels) to null so it doesn’t share the absolute value of the data but you can still see some sort of trend that is associated with it.</p>
<pre class="r"><code>presidential %&gt;%
  mutate(id = 33 + row_number()) %&gt;%
  ggplot(aes(start, id)) +
    geom_point() +
    geom_segment(aes(xend = end, yend = id)) +
    scale_x_date(NULL, breaks = presidential$start, date_labels = &quot;&#39;%y&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-61-1.png" width="672" /> Collectively axes and legends are called guides. Axes are used for x and y aesthetics; legends are used for everything else.</p>
<p>You can scale the dates such that in this plot it shows us when the president start and ended their term.</p>
<p>Note that the specification of breaks and labels for date and datetime scales is a little different:</p>
<p>date_labels takes a format specification, in the same form as parse_datetime().</p>
<p>date_breaks (not shown here), takes a string like “2 days” or “1 month”.</p>
<pre class="r"><code>base &lt;- ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class))

base + theme(legend.position = &quot;left&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<pre class="r"><code>base + theme(legend.position = &quot;top&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-2.png" width="672" /></p>
<pre class="r"><code>base + theme(legend.position = &quot;bottom&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-3.png" width="672" /></p>
<pre class="r"><code>base + theme(legend.position = &quot;right&quot;) # the default</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-4.png" width="672" /></p>
<p>You can edit the legend by changing its position on the graph, or you can set the legend position to none such that it won’t be anywhere.</p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  theme(legend.position = &quot;bottom&quot;) +
  guides(colour = guide_legend(nrow = 1, override.aes = list(size = 4)))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<pre class="r"><code>#&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p>To control the display of individual legends, use guides() along with guide_legend() or guide_colourbar(). The following example shows two important settings: controlling the number of rows the legend uses with nrow, and overriding one of the aesthetics to make the points bigger. This is particularly useful if you have used a low alpha to display many points on a plot.</p>
<pre class="r"><code>ggplot(diamonds, aes(carat, price)) +
  geom_bin2d()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<pre class="r"><code>ggplot(diamonds, aes(log10(carat), log10(price))) +
  geom_bin2d()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-64-2.png" width="672" /></p>
<pre class="r"><code>ggplot(diamonds, aes(carat, price)) +
  geom_bin2d() + 
  scale_x_log10() + 
  scale_y_log10()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-64-3.png" width="672" /> We can also change the scale of our plot. However it could be disadvantageous since the labels are now the transformed version of the data. This last example is the same but the axes are labeled on the original data scale.</p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv)) +
  scale_colour_brewer(palette = &quot;Set1&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-65-2.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv, shape = drv)) +
  scale_colour_brewer(palette = &quot;Set1&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-65-3.png" width="672" /> You can also change the color or these points to help people who may have colorblindness. We can also edit the shape of these points in the graph.</p>
<p>The ColorBrewer scales are documented online at <a href="http://colorbrewer2.org/" class="uri">http://colorbrewer2.org/</a> and made available in R via the RColorBrewer package, by Erich Neuwirth.</p>
<pre class="r"><code>presidential %&gt;%
  mutate(id = 33 + row_number()) %&gt;%
  ggplot(aes(start, id, colour = party)) +
    geom_point() +
    geom_segment(aes(xend = end, yend = id)) +
    scale_colour_manual(values = c(Republican = &quot;red&quot;, Democratic = &quot;blue&quot;))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
<pre class="r"><code>df &lt;- tibble(
  x = rnorm(10000),
  y = rnorm(10000)
)
ggplot(df, aes(x, y)) +
  geom_hex() +
  coord_fixed()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-66-2.png" width="672" /></p>
<pre class="r"><code>ggplot(df, aes(x, y)) +
  geom_hex() +
  viridis::scale_fill_viridis() +
  coord_fixed()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-66-3.png" width="672" /></p>
<p>You can also set the color manually.</p>
<p>For continuous colour, you can use the built-in scale_colour_gradient() or scale_fill_gradient(). If you have a diverging scale, you can use scale_colour_gradient2(). That allows you to give, for example, positive and negative values different colours. That’s sometimes also useful if you want to distinguish points above or below the mean.</p>
<p>Another option is scale_colour_viridis() provided by the viridis package. It’s a continuous analog of the categorical ColorBrewer scales. The designers, Nathaniel Smith and Stéfan van der Walt, carefully tailored a continuous colour scheme that has good perceptual properties. Here’s an example from the viridis vignette.</p>
<pre class="r"><code>ggplot(mpg, mapping = aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth() +
  coord_cartesian(xlim = c(5, 7), ylim = c(10, 30))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<pre class="r"><code>mpg %&gt;%
  filter(displ &gt;= 5, displ &lt;= 7, hwy &gt;= 10, hwy &lt;= 30) %&gt;%
  ggplot(aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-67-2.png" width="672" /></p>
<pre class="r"><code>suv &lt;- mpg %&gt;% filter(class == &quot;suv&quot;)
compact &lt;- mpg %&gt;% filter(class == &quot;compact&quot;)

ggplot(suv, aes(displ, hwy, colour = drv)) +
  geom_point()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-67-3.png" width="672" /></p>
<pre class="r"><code>ggplot(compact, aes(displ, hwy, colour = drv)) +
  geom_point()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-67-4.png" width="672" /></p>
<pre class="r"><code>x_scale &lt;- scale_x_continuous(limits = range(mpg$displ))
y_scale &lt;- scale_y_continuous(limits = range(mpg$hwy))
col_scale &lt;- scale_colour_discrete(limits = unique(mpg$drv))

ggplot(suv, aes(displ, hwy, colour = drv)) +
  geom_point() +
  x_scale +
  y_scale +
  col_scale</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-67-5.png" width="672" /></p>
<pre class="r"><code>ggplot(compact, aes(displ, hwy, colour = drv)) +
  geom_point() +
  x_scale +
  y_scale +
  col_scale</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-67-6.png" width="672" /></p>
<p>You can also set the limits on individual scales. Reducing the limits is basically equivalent to subsetting the data. It is generally more useful if you want expand the limits, for example, to match scales across different plots. For example, if we extract two classes of cars and plot them separately, it’s difficult to compare the plots because all three scales (the x-axis, the y-axis, and the colour aesthetic) have different ranges.</p>
<p>One way to overcome this problem is to share scales across multiple plots, training the scales with the limits of the full data. In this particular case, you could have simply used faceting, but this technique is useful more generally, if for instance, you want spread plots over multiple pages of a report.</p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  theme_bw()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<p>We can set themes for our plot as well and there are 8 built in ones for gg.plot.</p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) + geom_point()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&quot;my-plot.pdf&quot;)
#&gt; Saving 7 x 4.33 in image</code></pre>
<p>There are two main ways to get your plots out of R and into your final write-up: ggsave() and knitr. ggsave() will save the most recent plot to disk.</p>
<p>But if you don’t specify the width and the height it will just take from what the current plotting has. So for reproducability it is important to do these.</p>
<p>There are five main options that control figure sizing: fig.width, fig.height, fig.asp, out.width and out.height</p>
<p>They said they only use three out of the five :</p>
<p>“I find it most aesthetically pleasing for plots to have a consistent width. To enforce this, I set fig.width = 6 (6”) and fig.asp = 0.618 (the golden ratio) in the defaults. Then in individual chunks, I only adjust fig.asp.</p>
<p>I control the output size with out.width and set it to a percentage of the line width. I default to out.width = “70%” and fig.align = “center”. That give plots room to breathe, without taking up too much space.</p>
<p>To put multiple plots in a single row I set the out.width to 50% for two plots, 33% for 3 plots, or 25% to 4 plots, and set fig.align = “default”. Depending on what I’m trying to illustrate (e.g. show data or show plot variations), I’ll also tweak fig.width, as discussed below."</p>
<p>If you find that you’re having to squint to read the text in your plot, you need to tweak fig.width. If fig.width is larger than the size the figure is rendered in the final doc, the text will be too small; if fig.width is smaller, the text will be too big. You’ll often need to do a little experimentation to figure out the right ratio between the fig.width and the eventual width in your document.</p>
<p>If you want to make sure the font size is consistent across all your figures, whenever you set out.width, you’ll also need to adjust fig.width to maintain the same ratio with your default out.width.</p>
<p>He said the following: “I recommend setting fig.show =”hold" so that plots are shown after the code. This has the pleasant side effect of forcing you to break up large blocks of code with their explanations.</p>
<p>To add a caption to the plot, use fig.cap. In R Markdown this will change the figure from inline to “floating”."</p>
</div>
</div>
<div id="final" class="section level1">
<h1>Final</h1>
<pre class="r"><code>library(usmap)
library(ggplot2)

table12 &lt;- read.csv(file=&quot;table12.csv&quot;)
table11 &lt;- read.csv(file=&quot;table11.csv&quot;)</code></pre>
<div id="r-markdown" class="section level2">
<h2>R Markdown</h2>
<pre class="r"><code>summary(table12)</code></pre>
<pre><code>##  Participating.state.Federal Number.of.participating.agencies
##  Length:51                   Length:51                       
##  Class :character            Class :character                
##  Mode  :character            Mode  :character                
##                                                              
##                                                              
##                                                              
##  Population.covered Agencies.submitting.incident.reports
##  Length:51          Min.   :  0.00                      
##  Class :character   1st Qu.: 10.00                      
##  Mode  :character   Median : 22.00                      
##                     Mean   : 41.65                      
##                     3rd Qu.: 50.50                      
##                     Max.   :208.00                      
##  Total.number.of.incidents.reported
##  Length:51                         
##  Class :character                  
##  Mode  :character                  
##                                    
##                                    
## </code></pre>
<pre class="r"><code>table12$Number.of.participating.agencies &lt;- 
  as.integer(gsub(&quot;,&quot;, &quot;&quot;, table12$Number.of.participating.agencies))
table12$Population.covered &lt;- 
  as.integer(gsub(&quot;,&quot;, &quot;&quot;, table12$Population.covered))
table12$Total.number.of.incidents.reported &lt;-
  as.integer(gsub(&quot;,&quot;,&quot;&quot;,table12$Total.number.of.incidents.reported))

summary(table12)</code></pre>
<pre><code>##  Participating.state.Federal Number.of.participating.agencies
##  Length:51                   Min.   :   1.0                  
##  Class :character            1st Qu.: 102.5                  
##  Mode  :character            Median : 221.0                  
##                              Mean   : 304.7                  
##                              3rd Qu.: 437.5                  
##                              Max.   :1424.0                  
##  Population.covered Agencies.submitting.incident.reports
##  Min.   :   85670   Min.   :  0.00                      
##  1st Qu.: 1185942   1st Qu.: 10.00                      
##  Median : 3643904   Median : 22.00                      
##  Mean   : 5985965   Mean   : 41.65                      
##  3rd Qu.: 7209156   3rd Qu.: 50.50                      
##  Max.   :39502561   Max.   :208.00                      
##  Total.number.of.incidents.reported
##  Min.   :   0                      
##  1st Qu.:  21                      
##  Median :  65                      
##  Mean   : 141                      
##  3rd Qu.: 169                      
##  Max.   :1015</code></pre>
<p><First check if there is a correlation with the number of agencies participating
and the population> <img src="Journal_files/figure-html/pressure-1.png" width="672" /><img src="Journal_files/figure-html/pressure-2.png" width="672" /></p>
<pre><code>## [1] 0.7281031</code></pre>
<p><See how many of agencies are submitting reports out of number submitting> <data shows that a very low number agencies are actually submitting reports></p>
<pre class="r"><code>percent_participate_table &lt;- data.frame(table12$Participating.state.Federal,
                                  table12$Agencies.submitting.incident.reports,
                                  table12$Number.of.participating.agencies)

colnames(percent_participate_table) &lt;- c(&#39;States&#39;, &#39;Agencies Submitting Reports&#39;
                                         , &quot;Agencies Participating&quot;)

percent_participate_table = transform(percent_participate_table, 
                            freq = (percent_participate_table$`Agencies Submitting Reports`/percent_participate_table$`Agencies Participating`)*100)</code></pre>
<p>&lt;there is a correlation -&gt; Lets see if we can predict the n&gt; <first lets see if the number of ag></p>
<pre class="r"><code>plot(table12$Number.of.participating.agencies, table12$Total.number.of.incidents.reported, 
                                  xlab=&quot;Population&quot;, ylab=&quot;Number of Agencies&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<pre class="r"><code>plot(table12$Number.of.participating.agencies, table12$Total.number.of.incidents.reported, 
                                  xlab=&quot;Number of agencies&quot;, 
                                  ylab=&quot;Number of incidents&quot;, 
                                  xlim = range(0, 800))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-73-2.png" width="672" /></p>
<pre class="r"><code>cor(table12$Number.of.participating.agencies, table12$Total.number.of.incidents.reported)</code></pre>
<pre><code>## [1] 0.4458242</code></pre>
<p><lets see if there is an increase of agencies means an increase of reports></p>
<pre class="r"><code>partagent &lt;-table12$Number.of.participating.agencies
reported &lt;-table12$Total.number.of.incidents.reported
lm_agencies_report &lt;- lm(formula = partagent ~ reported,
                         data = table12)
summary(lm_agencies_report)</code></pre>
<pre><code>## 
## Call:
## lm(formula = partagent ~ reported, data = table12)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -354.40 -153.95  -92.78  100.04 1183.17 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 214.6460    44.2994   4.845 0.0000131 ***
## reported      0.6385     0.1831   3.486   0.00104 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 257.1 on 49 degrees of freedom
## Multiple R-squared:  0.1988, Adjusted R-squared:  0.1824 
## F-statistic: 12.16 on 1 and 49 DF,  p-value: 0.001043</code></pre>
<p><linear regression assumptions test></p>
<pre class="r"><code>plot(partagent, lm_agencies_report$residuals, main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Scaled speed&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<pre class="r"><code>plot(lm_agencies_report, which=3)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
<pre class="r"><code>plot(lm_agencies_report, which=5)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<pre class="r"><code>plot(lm_agencies_report, which=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-77-2.png" width="672" /> &lt;a regression isn’t valid so we can’t say that for every predicted agencies that we get more reports&gt;</p>
<p><now look at the number of offenses we are seeing across state lines></p>
<pre class="r"><code>summary(table11)</code></pre>
<pre><code>##  Participating.state.Federal Total.offenses  
##  Length:51                   Min.   :   0.0  
##  Class :character            1st Qu.:  28.5  
##  Mode  :character            Median :  82.0  
##                              Mean   : 164.2  
##                              3rd Qu.: 195.0  
##                              Max.   :1221.0  
##  Murder.and.nonnegligent.manslaughter      Rape        Aggravated.assault
##  Min.   : 0.0000                      Min.   :0.0000   Min.   :  0.00    
##  1st Qu.: 0.0000                      1st Qu.:0.0000   1st Qu.:  3.00    
##  Median : 0.0000                      Median :0.0000   Median :  9.00    
##  Mean   : 0.6471                      Mean   :0.5882   Mean   : 21.67    
##  3rd Qu.: 0.0000                      3rd Qu.:0.0000   3rd Qu.: 22.00    
##  Max.   :22.0000                      Max.   :8.0000   Max.   :290.00    
##  Simple.assault    Intimidation    Human.Trafficking.Commercial.Sex.Acts
##  Min.   :  0.00   Min.   :  0.00   Min.   :0.00000                      
##  1st Qu.:  6.00   1st Qu.:  4.50   1st Qu.:0.00000                      
##  Median : 18.00   Median : 17.00   Median :0.00000                      
##  Mean   : 39.55   Mean   : 41.71   Mean   :0.05882                      
##  3rd Qu.: 50.00   3rd Qu.: 42.00   3rd Qu.:0.00000                      
##  Max.   :272.00   Max.   :264.00   Max.   :2.00000                      
##      Other           Robbery          Burglary      Larceny..theft  
##  Min.   :0.0000   Min.   : 0.000   Min.   : 0.000   Min.   : 0.000  
##  1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.: 0.000  
##  Median :0.0000   Median : 1.000   Median : 1.000   Median : 2.000  
##  Mean   :0.8039   Mean   : 2.451   Mean   : 2.235   Mean   : 5.529  
##  3rd Qu.:0.5000   3rd Qu.: 2.000   3rd Qu.: 2.500   3rd Qu.: 4.500  
##  Max.   :7.0000   Max.   :35.000   Max.   :20.000   Max.   :80.000  
##  Motor.vehicle.theft     Arson       Destruction..damage..vandalism
##  Min.   :0.0000      Min.   :0.000   Min.   :  0.00                
##  1st Qu.:0.0000      1st Qu.:0.000   1st Qu.:  6.00                
##  Median :0.0000      Median :0.000   Median : 14.00                
##  Mean   :0.3725      Mean   :0.902   Mean   : 41.92                
##  3rd Qu.:0.0000      3rd Qu.:1.000   3rd Qu.: 43.50                
##  Max.   :7.0000      Max.   :9.000   Max.   :379.00                
##     Other.1       Crimes.against.society
##  Min.   : 0.000   Min.   : 0.000        
##  1st Qu.: 0.000   1st Qu.: 0.000        
##  Median : 0.000   Median : 1.000        
##  Mean   : 1.118   Mean   : 4.627        
##  3rd Qu.: 1.000   3rd Qu.: 5.500        
##  Max.   :11.000   Max.   :43.000</code></pre>
<p>&lt;total offences in general looking at freq from table 12 to table 11&gt;</p>
<pre class="r"><code>table11_total = data.frame(table11$Participating.state.Federal, table11$Total.offenses, percent_participate_table$freq)</code></pre>
<p><most common crimes per state></p>
<pre class="r"><code>table11_maxperstate &lt;- data.frame(table11$Participating.state.Federal)
table11_maxperstate[&#39;max&#39;] &lt;- apply(table11[3:15], 1, max)
table11_maxperstate[&#39;highest occuring crimes&#39;] &lt;- colnames(table11[3:15])[max.col(table11[3:15], ties.method = &quot;first&quot;)]

table11_total</code></pre>
<pre><code>##    table11.Participating.state.Federal table11.Total.offenses
## 1                              Alabama                      0
## 2                               Alaska                     17
## 3                              Arizona                    254
## 4                             Arkansas                     10
## 5                           California                   1221
## 6                             Colorado                    257
## 7                          Connecticut                     86
## 8                             Delaware                     27
## 9                 District of Columbia                    247
## 10                             Florida                    131
## 11                             Georgia                    123
## 12                              Hawaii                     51
## 13                               Idaho                     38
## 14                            Illinois                     95
## 15                             Indiana                     87
## 16                                Iowa                     13
## 17                              Kansas                     99
## 18                            Kentucky                    179
## 19                           Louisiana                     33
## 20                               Maine                     24
## 21                            Maryland                     18
## 22                       Massachusetts                    441
## 23                            Michigan                    495
## 24                           Minnesota                    123
## 25                         Mississippi                     15
## 26                            Missouri                    106
## 27                             Montana                     35
## 28                            Nebraska                     57
## 29                              Nevada                     53
## 30                       New Hampshire                     17
## 31                          New Jersey                    478
## 32                          New Mexico                     63
## 33                            New York                    618
## 34                      North Carolina                    248
## 35                        North Dakota                     20
## 36                                Ohio                    428
## 37                            Oklahoma                     30
## 38                              Oregon                    205
## 39                        Pennsylvania                     50
## 40                        Rhode Island                     21
## 41                      South Carolina                     82
## 42                        South Dakota                     21
## 43                           Tennessee                    152
## 44                               Texas                    560
## 45                                Utah                     34
## 46                             Vermont                     37
## 47                            Virginia                    185
## 48                          Washington                    664
## 49                       West Virginia                     36
## 50                           Wisconsin                     83
## 51                             Wyoming                      6
##    percent_participate_table.freq
## 1                        0.000000
## 2                       15.151515
## 3                       18.478261
## 4                        2.158273
## 5                       26.458616
## 6                       22.624434
## 7                       39.215686
## 8                       15.873016
## 9                      100.000000
## 10                       7.993730
## 11                      10.101010
## 12                     100.000000
## 13                       8.490566
## 14                       3.159341
## 15                      10.747664
## 16                       3.252033
## 17                      14.058355
## 18                      16.341463
## 19                       8.029197
## 20                       7.462687
## 21                       5.882353
## 22                      23.055556
## 23                      29.467085
## 24                       9.234828
## 25                      11.904762
## 26                       4.903678
## 27                      15.533981
## 28                      17.692308
## 29                      10.416667
## 30                       7.446809
## 31                      37.410072
## 32                      26.086957
## 33                      11.648746
## 34                      24.096386
## 35                      11.009174
## 36                      24.319419
## 37                       5.022831
## 38                      22.549020
## 39                       1.053371
## 40                      20.833333
## 41                       8.888889
## 42                      10.156250
## 43                       9.032258
## 44                      15.769594
## 45                      11.570248
## 46                      19.101124
## 47                      13.734940
## 48                      30.434783
## 49                       7.500000
## 50                       9.839817
## 51                       9.090909</code></pre>
<pre class="r"><code>table11_maxperstate</code></pre>
<pre><code>##    table11.Participating.state.Federal max              highest occuring crimes
## 1                              Alabama   0 Murder.and.nonnegligent.manslaughter
## 2                               Alaska   6                   Aggravated.assault
## 3                              Arizona 110                         Intimidation
## 4                             Arkansas   4                   Aggravated.assault
## 5                           California 330       Destruction..damage..vandalism
## 6                             Colorado  70                         Intimidation
## 7                          Connecticut  37                         Intimidation
## 8                             Delaware  12                         Intimidation
## 9                 District of Columbia 113                       Simple.assault
## 10                             Florida  43                       Simple.assault
## 11                             Georgia  47                       Simple.assault
## 12                              Hawaii  23                       Simple.assault
## 13                               Idaho  14                         Intimidation
## 14                            Illinois  39                       Simple.assault
## 15                             Indiana  36                         Intimidation
## 16                                Iowa   4                       Simple.assault
## 17                              Kansas  26                         Intimidation
## 18                            Kentucky  66                         Intimidation
## 19                           Louisiana   9                       Simple.assault
## 20                               Maine  17                         Intimidation
## 21                            Maryland  12       Destruction..damage..vandalism
## 22                       Massachusetts 169                         Intimidation
## 23                            Michigan 152                         Intimidation
## 24                           Minnesota  35                         Intimidation
## 25                         Mississippi   3       Destruction..damage..vandalism
## 26                            Missouri  33                       Simple.assault
## 27                             Montana  14       Destruction..damage..vandalism
## 28                            Nebraska  16                       Simple.assault
## 29                              Nevada  15       Destruction..damage..vandalism
## 30                       New Hampshire   7       Destruction..damage..vandalism
## 31                          New Jersey 267       Destruction..damage..vandalism
## 32                          New Mexico  22                       Simple.assault
## 33                            New York 379       Destruction..damage..vandalism
## 34                      North Carolina  91                         Intimidation
## 35                        North Dakota   8                         Intimidation
## 36                                Ohio 107                         Intimidation
## 37                            Oklahoma  11       Destruction..damage..vandalism
## 38                              Oregon  60       Destruction..damage..vandalism
## 39                        Pennsylvania  18                         Intimidation
## 40                        Rhode Island  11       Destruction..damage..vandalism
## 41                      South Carolina  18                         Intimidation
## 42                        South Dakota   9                       Simple.assault
## 43                           Tennessee  37                       Simple.assault
## 44                               Texas 127                       Simple.assault
## 45                                Utah   9                   Aggravated.assault
## 46                             Vermont  23       Destruction..damage..vandalism
## 47                            Virginia  55                       Simple.assault
## 48                          Washington 259                         Intimidation
## 49                       West Virginia   8                         Intimidation
## 50                           Wisconsin  25                       Simple.assault
## 51                             Wyoming   2                       Simple.assault</code></pre>
<pre class="r"><code>incidents &lt;- data.frame(table12$Participating.state.Federal, as.numeric(gsub(&quot;,&quot;,&quot;&quot;,table12$Total.number.of.incidents.reported)))
colnames(incidents) &lt;- c(&#39;state&#39;, &#39;Total number of incidents&#39;)
plot_usmap(data = incidents, values = &quot;Total number of incidents&quot;)+scale_fill_continuous(name = &quot;Number of Incidents&quot;,low = &quot;white&quot;, high =&quot;darkblue&quot;, label = scales::comma) + theme(legend.position = &quot;right&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<pre class="r"><code>percent_participate_table &lt;- data.frame(table12$Participating.state.Federal,
                                  table12$Agencies.submitting.incident.reports,
                                  table12$Number.of.participating.agencies)

colnames(percent_participate_table) &lt;- c(&#39;state&#39;, &#39;Agencies Submitting Reports&#39;
                                         , &quot;Agencies Participating&quot;)

percent_participate_table = transform(percent_participate_table, freq = (percent_participate_table$`Agencies Submitting Reports`/percent_participate_table$`Agencies Participating`)*100)


plot_usmap(data = percent_participate_table, values = &quot;freq&quot;)+scale_fill_continuous(name = &quot;Percent of Participating Agencies&quot;,low = &quot;white&quot;, high =&quot;darkblue&quot;, label = scales::comma) + theme(legend.position = &quot;right&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<pre class="r"><code>colnames(table11_maxperstate) &lt;- c(&#39;state&#39;, &quot;max&quot;, &quot;incidents&quot;)
plot_usmap(data = table11_maxperstate, values = &quot;incidents&quot;) + theme(legend.position = &quot;right&quot;) + scale_fill_brewer(name = &quot;Incidents with the highest occurrence&quot;,type = &#39;qual&#39;, palette = 1) </code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
